---
title: RAG-Learning
date: 2025-03-27 15:59:45
tags:
---

>llm-universe 学习笔记

本篇记录了从0-1构建RAG应用的过程

## RAG简单入门介绍


大语言模型在处理一些问题的时候难以提供准确答案，研究人员为了解决这问题提出了RAG（检索增强生成）架构。该架构巧妙地**整合了从庞大知识库中检索到的相关信息，并以此为基础，指导大型语言模型生成更为精准的答案**。其能很大程度上解决LLM幻觉、知识更新迭代困难那等缺点。用一个比较通俗的比喻就是：RAG是LLM的一个专业背包，可以在特定场合支援LLM，并随时更换。

提到RAG就不得不提到Finetune（微调），作为主流的提升模型的方式，两者各有优势。整体来说RAG更方便，更易追溯，能更好减少幻觉。

### 大致工作流程：

Dh认为：你怎么查字典的，RAG就咋工作的
1. **数据处理阶段**
    1. 对原始数据进行清洗和处理。
    2. 将处理后的数据转化为检索模型可以使用的格式。
    3. 将处理后的数据存储在对应的数据库中。
2. **检索阶段**
    4. 将用户的问题输入到检索系统中，从数据库中检索相关信息。
3. **增强阶段**
    1. 对检索到的信息进行处理和增强，以便生成模型可以更好地理解和使用。
4. **生成阶段**
    2. 将增强后的信息输入到生成模型中，生成模型根据这些信息生成答案。

## Langchain
---

**LangChain 框架是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程**
目前比较稳定的版本是v0.1.0

### 核心组件

- **模型输入/输出（Model I/O）**：与语言模型交互的接口
- **数据连接（Data connection）**：与特定应用程序的数据进行交互的接口
- **链（Chains）**：将组件组合实现端到端应用。比如搭建检索问答链来完成检索问答。
- **记忆（Memory）**：用于链的多次运行之间持久化应用程序状态；
- **代理（Agents）**：扩展模型的推理能力。用于复杂的应用的调用序列；
- **回调（Callbacks）**：扩展模型的推理能力。用于复杂的应用的调用序列

### 生态

- LangChain Community：专注第三方集成。
- LangChain Core：提供核心组件。
- LangChain CLI：命令行工具，便于终端交互。
- LangServe：部署服务
- LangSmith：开发者平台

## 模型开发


大模型开发是一个工程问题，基本不会改变模型本身而是**将大模型作为一个调用工具，通过 Prompt Engineering、数据工程、业务逻辑分解等手段来充分发挥大模型能力，适配应用任务**。

其实模型为核心的开发与传统的AI开发有很大的不同，传统的AI开发是改变/训练模型，但是大语言模型的指令遵循和文本生成让开发者用Prompt Engineering就可以平替。在评估体系上，传统AI开发可能要有训练集、测试集、验证集。但是大模型开发则可以从需求出发构建更小的验证集，再优化流程和 Prompt。

### 模型开发步骤

- **明确目标，设计功能（核心、上游、下游）以及大致实现逻辑。**
小白在开发过程中（Dh也是）常会用到cursor，而cursor使用的时候越清晰的产品规划越能让cursor生成出高质量的代码。
- **搭建整体架构**
绝大部分大模型应用都是采用的特定数据库 + Prompt + 通用大模型的架构。框架建议用langchain、LlamaIndex。
- **搭建数据库**
个性化大模型应用需要有个性化数据库进行支撑。由于大模型应用需要进行向量语义检索，一般使用诸如 Chroma 的向量数据库。
数据要先进行预处理，再向量化存储到数据库中。数据预处理一般包括从多种格式向纯文本的转化，以及对错误数据、异常数据、脏数据的清洗。完成预处理后，需要进行切片、向量化构建出个性化数据库。
- **Prompt Engineering**
- **验证迭代**
寻找Bad case 改进模型方案
- **前后端的搭建**
Gradio 和 Streamlit比较合适
- **体验优化**

### 基本概念

- Prompt：提示词
- Temperature：控制随机性和创造性
- System Prompt：随着ChatGPT API开放兴起的一个概念，并不在大模型本身训练中得到体现，而是大模型服务方为用户体验所设置的一种策略。System Prompt相比于普通的Prompt有更高的优先级，一般只有一个
### 关于Prompt 技巧

其实Prompt已经是一个老生长谈的话题了
**清晰、具体的指令**
- 用分割符
- 避免提示词注入
- few shot
**给模型思考的时间**
**先让模型自己想一个解法**

## 搭建知识库


### 词向量

词向量（Embeddings）是一种将非结构化数据，如单词、句子或者整个文档，转化为实数向量的技术。构建词向量可以使用嵌入模型（可以用API也可以用本地），这些实数向量相比于文字可以被计算机更好地理解和处理，同时综合能力更强。我们会把词向量储存在向量数据库中，它的处理效率明显高于传统数据库，常见的有：Chroma、Weaviate、Qdrant.....

形成词向量之前，我们要先进行数据预处理：数据选取、文档转化、数据清洗、文档分割。注意：文档分割是非常重要的一个环节，有多种分割方式。RAG的好坏很大程度上取决于文档分割的方式。

### 数据处理

一般选取word、pdf、md格式的文件作为源文档，LangChain 的 PyMuPDFLoader可以读取文档，然后通过正则化、replace等方式去除一些杂乱的字符。接着通过文档分割，Langchain 中文本分割器都根据 `chunk_size` (块大小)和 `chunk_overlap` (块与块之间的重叠大小)。

### 向量检索

构建向量库之后，要进行向量检索，有两种常见的向量检索方式：相似度检索和MMR检索。chroma的检索方式是余弦距离检索，然而一味考虑相关性会让内容比较单一，所以使用最大边际相关性 (`MMR, Maximum marginal relevance`) 帮助我们在保持相关性的同时，增加内容的丰富度。他的核心思想是在已经选择了一个相关性高的文档之后，再选择一个与已选文档相关性较低但是信息丰富的文档。这样可以在保持相关性的同时，增加内容的多样性，避免过于单一的结果。

## 系统评估与优化方法


在搭建完毕应用之后，下一步要做的其实就是评估，不同于传统的AI开发，大模型开发不需要很多验证集合，可以在尝试中找到bad case把他们加入到验证集合里面去，再做一些衡量指标，但这其实不是必须的，可以随时停止。

人工评估在项目初期是必不可少的，遵循几个准则：量化评估、多为评估（知识查找正确性、回答一致性、幻觉比例、逻辑性......）。当然，人工费时费力，我们可以让大模型扮演评估者去用我们给定的方式打分。

但这时候，随着加入的bad case越来越多，如果还要手动去调试就很难受了，我们可以定义一种简单的评估方式。下面介绍两种方法：

方法一：构造客观题
将主观题变成选择题，但是要注意的是大模型可能会输出除了ABCD之外的汉字，要在做自动评分的时候注意一下，另外错选和不选应该要区分，同样的给分会鼓励模型出现幻觉。

方法二：计算相似度
针对主观题我们构建一个标准答案，然后可以用nltk库中的bleu函数进行一个打分，但是由于大模型的回答在关键地方的不同可能就会造成整个答案的意思不同，然而bleu仅仅是评判相似度的，所以要根据具体的业务场景进行调整。

当然，我们还可以随机组合，在不同维度采用混合评估的方式。

### 关于生成部分与检索部分

RAG全程是检索增强生成，那么既然要优化就聚焦于检索和生成两部分。检索部分的核心功能是保证系统根据用户 query 能够查找到对应的答案片段，而生成部分的核心功能即是保证系统在获得了正确的答案片段之后，可以充分发挥大模型能力生成一个满足用户要求的正确回答。
- **生成部分**
	**修改Prompt**，提升直观回答质量、标注信息来源。
	
	**构造思维链**，比如加入反思过程，或者让他step by step。
	
	**增加指令解析**：这个思路其实和Agent的思路非常类似，设置一个 LLM（即 Agent）来理解指令，判断指令需要执行什么工具，再针对性调用需要执行的工具，其中每一个工具可以是基于
	不同Prompt Engineering 的 LLM，也可以是例如数据库、API 等。

- **检索部分**
	**定义评估方式**：
		对于 N 个给定 query，我们保证每一个 query 对应的正确答案都存在于知识库中。假设对于每一个 query，系统找到了 K 个文本片段，如果正确答案在 K 个文本片段之一，那么我们认为检索成功；如果正确答案不在 K 个文本片段之一，我们任务检索失败。准确率=M/N，其中M是成功检索的query的个数。
	
	**优化检索思路：**
		**知识片断割裂导致答案丢失**：优化文本切割，用语义分割或者人工分割等方式入手。
		**query提问需要上下文概括回答**：由于模型上下文限制，导致出现问题，通过使用 LLM 来对长文档进行概括总结，或者预设提问让 LLM 做出回答，从而将此类问题的可能答案预先填入知识库作为单独的 chunk，来一定程度解决该问题。
		**关键词误导**：对用户的query进行改写，要求llm对query进行提炼。
		**匹配关系不合理**：选取更好的向量模型。

## 结语

llm-universe真的是非常好的教程，特别是跟着手动搭建了属于自己的知识库助手，非常有成就感。推荐去学习一下：https://datawhalechina.github.io/llm-universe/